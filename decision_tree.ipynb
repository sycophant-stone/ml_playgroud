{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataset():\n",
    "    dataset=[[1,1,'yes'],\n",
    "             [1,1,'yes'],\n",
    "             [1,0,'no'],\n",
    "             [0,1,'no'],\n",
    "             [0,1,'no'],]\n",
    "    labels=['no surfacing','flippers']\n",
    "    return dataset,labels\n",
    "\n",
    "X_train,y_train=createDataset()\n",
    "labels=y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 计算熵,entrop\n",
    "\n",
    "$$\\sum_{k=0}^{K} -p_{k}log_{2}p_{k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcShannonEnt(dataset):\n",
    "    numItems=len(dataset)\n",
    "    labelCounts={}\n",
    "    for itemset in dataset:\n",
    "        currentLabel=itemset[-1]\n",
    "        if currentLabel not in labelCounts.keys(): \n",
    "            labelCounts[currentLabel]=0\n",
    "        labelCounts[currentLabel]+=1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numItems\n",
    "        shannonEnt-=prob*log(prob,2)\n",
    "    return shannonEnt\n",
    "\n",
    "calcShannonEnt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 'yes'], [1, 'yes'], [0, 'no']]\n",
      "[[1, 'no'], [1, 'no']]\n",
      "[[1, 'no']]\n",
      "[[1, 'yes'], [1, 'yes'], [0, 'no'], [0, 'no']]\n",
      "[[1, 1], [1, 1]]\n",
      "[[1, 0], [0, 1], [0, 1]]\n"
     ]
    }
   ],
   "source": [
    "# splitDataSet\n",
    "# 在dataSet中取出第axis个元素.并判断这个元素值和value是否相等.\n",
    "# 如果相等,这个vector取出来,并把当前的axis的这个元素从这个vector中删除.\n",
    "# 并以此重新组成一个retDataSet,也就是剩下的Data集.\n",
    "\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]     # 扣掉这个axis描述的内容.\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)   # 添加到retDataSet中\n",
    "    return retDataSet\n",
    "\n",
    "T=splitDataSet(X_train,0,1)\n",
    "print(T)\n",
    "T=splitDataSet(X_train,0,0)\n",
    "print(T)\n",
    "T=splitDataSet(X_train,1,0)\n",
    "print(T)\n",
    "T=splitDataSet(X_train,1,1)\n",
    "print(T)\n",
    "T=splitDataSet(X_train,2,'yes')\n",
    "print(T)\n",
    "T=splitDataSet(X_train,2,'no')\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 'yes']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(X_train[0])\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g(D,A)\n",
    "\n",
    "1.信息增益\n",
    "$$g(D,A)=H(D)-H(D|A)$$\n",
    "\n",
    "2.信息熵\n",
    "$$H(D)=\\sum_{k=1}^{K}\\frac{|C_k|}{N}log\\frac{|C_k|}{N}$$\n",
    "\n",
    "3.H(D|A)\n",
    "$$H(D|X^{(A)}=a_i)=\\sum_{k=1}^{K}-(\\frac{N_{ik}}{N_i}log\\frac{N_{ik}}{N_i})$$\n",
    "\n",
    "$$H(D|A)=\\sum_{i=1}^{N}P_A(X^{A})H(D|X^{A}=a_i)=\\sum_{i=1}^{N}\\frac{N_i}{N}*\\sum_{k=1}^{K}-(\\frac{N_{ik}}{N_i}log\\frac{N_{ik}}{N_i})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures=len(dataSet[0])-1\n",
    "    baseEntropy=calcShannonEnt(dataSet)\n",
    "    bestInfoGain=0.0\n",
    "    bestFeature=-1\n",
    "    for i in range(numFeatures): # 一共2个feature. 依次取第一个和第二个feature.\n",
    "        featList=[example[i] for example in dataSet] # 所有的dataSet中取出第一个\n",
    "        #print(\"featList\",featList)\n",
    "        uniqueVals=set(featList) # 这个应该是种类的个数. 比如第一个feature有两类,\"1\"和\"0\"\n",
    "        newEntropy=0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet=splitDataSet(dataSet,i,value)\n",
    "            #print(\"subDataSet\",subDataSet)\n",
    "            #print(\"len(subDataSet)\",len(subDataSet))\n",
    "            #print(\"len(dataSet)\",len(dataSet))\n",
    "            prob=len(subDataSet)/float(len(dataSet)) # 算的 Ni/N\n",
    "            newEntropy+=prob*calcShannonEnt(subDataSet) # 算的H(D|A)\n",
    "        infoGain = baseEntropy-newEntropy \n",
    "        if(infoGain>bestInfoGain): # 找到最大的信息熵对应的feature\n",
    "            bestInfoGain=infoGain\n",
    "            bestFeature=i\n",
    "    return bestFeature\n",
    "\n",
    "chooseBestFeatureToSplit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classList ['yes', 'yes', 'no', 'no', 'no']\n",
      "classList ['no', 'no']\n",
      "classList ['yes', 'yes', 'no']\n",
      "classList ['no']\n",
      "classList ['yes', 'yes']\n"
     ]
    }
   ],
   "source": [
    "def majorityCnt(classList):\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys(): \n",
    "            classCount[vote]=0\n",
    "        classCount[vote]+=1\n",
    "    sortedClassCount=sorted(classCount.iteritems(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "def createTree(dataSet,labels):\n",
    "    classList=[example[-1] for example in dataSet]\n",
    "    print(\"classList\",classList)\n",
    "    \n",
    "    # 两个结束条件\n",
    "    if classList.count(classList[0])==len(classList): # 该叶子节点只有一个成员了.就退出\n",
    "        return classList[0]\n",
    "    \n",
    "    if len(dataSet[0])==1:\n",
    "        return majorityCnt(classList) # 如果某个子集中都是同一类的,就不用再分了.\n",
    "    \n",
    "    bestFeat=chooseBestFeatureToSplit(dataSet) # 算出当前dataSet中最大熵的feature.\n",
    "    bestFeatLabel=labels[bestFeat]\n",
    "    #print(\"bestFeat\",bestFeat)\n",
    "    #print(\"bestFeatLabel\",bestFeatLabel)\n",
    "    myTree={bestFeatLabel:{}}\n",
    "    del(labels[bestFeat])\n",
    "    featValues=[example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:] # 拷贝\n",
    "        myTree[bestFeatLabel][value]=createTree(splitDataSet(dataSet,bestFeat,value),subLabels)\n",
    "    \n",
    "    return myTree\n",
    "\n",
    "        \n",
    "#createTree(X_train[:-1],X_train[-1])\n",
    "mytree=createTree(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "no\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "def classify(inputTree,featLabels,testVec):\n",
    "    firstStr = list(inputTree.keys())[0]\n",
    "    secondDict = inputTree[firstStr]\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    key = testVec[featIndex]\n",
    "    valueOfFeat = secondDict[key]\n",
    "    if isinstance(valueOfFeat, dict): \n",
    "        classLabel = classify(valueOfFeat, featLabels, testVec)\n",
    "    else: classLabel = valueOfFeat\n",
    "    return classLabel\n",
    "\n",
    "print(classify(mytree,labels,[1,0]))\n",
    "print(classify(mytree,labels,[0,1]))\n",
    "print(classify(mytree,labels,[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
